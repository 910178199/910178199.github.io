<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[简要算法]]></title>
      <url>%2F2016%2F12%2F18%2F%E6%91%98%E8%A6%81%E7%AE%97%E6%B3%95%2F</url>
      <content type="text"><![CDATA[Python的hashlib提供了常见的摘要算法，如MD5，SHA1等等。摘要算法就是通过摘要函数f()对任意长度的数据data计算出固定长度的摘要digest，目的是为了发现原始数据是否被人篡改过。 摘要算法之所以能指出数据是否被篡改过，就是因为摘要函数是一个单向函数，计算f(data)很容易，但通过digest反推data却非常困难。而且，对原始数据做一个bit的修改，都会导致计算出的摘要完全不同。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# -*- coding=utf-8 -*-'haslib摘要算法'import hashlib# MD5加密md5 = hashlib.md5()md5.update('my name '.encode('utf-8'))md5.update('is lijian'.encode('utf-8'))print(md5.hexdigest())# SHA1加密sha1 = hashlib.sha1()sha1.update('my name'.encode('utf-8'))sha1.update('is lijian'.encode('utf-8'))print(sha1.hexdigest())# 练习def calc_md5(password): md5 = hashlib.md5() md5.update(str(password).encode('utf-8')) return md5.hexdigest()print(calc_md5('123456'))# 练习二：db = &#123; 'michael': 'e10adc3949ba59abbe56e057f20f883e', 'bob': '878ef96e86145580c38c87f0410ad153', 'alice': '99b1c2188db85afee403b1536010c2c9'&#125;def login(user, password): if calc_md5(password) == db[user]: return True else: return Falseprint(login('bob', 'abc999'))# 练习三：def get_md5(age): md5 = hashlib.md5() md5.update(str(age).encode('utf-8')) return md5.hexdigest()def register(username, password): r = get_md5(password + username + 'the-Salt') db[username] = r return rdef login(username,password): r = get_md5(password + username + 'the-Salt') if db[username]== r: print('True') else: print('False')print(register('123','123'))login('123','123')print(db)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[strucr]]></title>
      <url>%2F2016%2F12%2F18%2Fstruct%2F</url>
      <content type="text"><![CDATA[Python提供了一个struct模块来解决bytes和其他二进制数据类型的转换。 12345678910'struct:解决bytes和其他二进制数据类型转换'import structprint(struct.pack('&gt;I', 10240099))# pack的第一个参数是处理指令，'&gt;I'的意思是：# &gt;表示字节顺序是big-endian，也就是网络序，I表示4字节无符号整数。# 后面的参数个数要和处理指令一致。print(struct.unpack('&gt;IH', b'\xf0\xf0\xf0\xf0\x80\x80'))]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[base64]]></title>
      <url>%2F2016%2F12%2F17%2Fbase64%2F</url>
      <content type="text"><![CDATA[123456789101112131415161718192021# -*- coding=utf-8 -*-'base64'import base64#编码b = base64.b64encode(b'binary\x00string')print(base64.b64encode(b'i\xb7\x1d\xfb\xef\xff'))#标准的Base64编码后可能出现字符+和/，在URL中就不能直接作为参数，#所以又有一种"url safe"的base64编码，其实就是把字符+和/分别变成-和_print(base64.urlsafe_b64encode(b'i\xb7\x1d\xfb\xef\xff'))print(b)#解码print(base64.urlsafe_b64decode('abcd--__'))de= base64.b64decode(b)print(de)#小结# Base64是一种任意二进制到文本字符串的编码方法，常用于在URL、Cookie、网页中传输少量二进制数据。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[collections]]></title>
      <url>%2F2016%2F12%2F17%2Fcollections%2F</url>
      <content type="text"><![CDATA[collections是Python内建的一个集合模块，提供了许多有用的集合类。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253'collections集合模块，提供了许多有用的集合类。'from collections import namedtuplePoint = namedtuple('Point', ['x', 'y', 'z'])p = Point(1, 2, 3)print(p.x, p.y, p.z)# namedtuple：是一个函数，它用来创建一个自定义的tuple对象，# 并且规定了tuple元素的个数，并可以用属性而不是索引来引用tuple的某个元素。print(isinstance(p, Point))print(isinstance(p, tuple))# deque：是为了高效实现插入和删除操作的双向列表，适合用于队列和栈from collections import dequeq = deque(['a', 'b', 'c'])q.append('x')# 在头部添加q.appendleft('y')# deque除了实现list的append()和pop()外，# 还支持appendleft()和popleft()，这样就可以非常高效地往头部添加或删除元素。print(q)q.popleft()q.pop()print(q)# defaultdict：使用dict时，如OrderedDict果引用的Key不存在，就会抛出KeyError。# 如果希望key不存在时，返回一个默认值from collections import defaultdictdf = defaultdict(lambda: 'defa')df['a'] = 1print(df['a'])#不存在返回默认值print(df['b'])#OrderedDict：在dict中保持key的顺序from collections import OrderedDictd = dict([('a', 1), ('b', 2), ('c', 3)])print(d)#保持插入顺序o = OrderedDict([('a', 1), ('b', 2), ('c', 3)])print(o)#Counter：计数器from collections import Counter#统计出现的次数c = Counter()for x in '1233': c[x] = c[x]+1]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[datetime]]></title>
      <url>%2F2016%2F12%2F16%2Fdatetime%2F</url>
      <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081# -*- coding=utf-8 -*-'datetime 时间类'# datetime模块还包含一个datetime类，# 通过from datetime import datetime导入的才是datetime这个类。from datetime import datetime# 当前时间now = datetime.now()print(now)# 输入时间转换dt = datetime(2016, 1, 1, 20)print(dt)# datetime转换为timestamp(时间戳)# 时间转换为时间戳time = dt.timestamp()print(time)# 注意Python的timestamp是一个浮点数。如果有小数位，小数位表示毫秒数。# timestamp转换为datetime# 时间戳转换为时间d = datetime.fromtimestamp(time)print(d)# 转换为格林尼治时间utc = datetime.utcfromtimestamp(time)print(utc)# str转换为datetimeday = datetime.strptime('2016-12-12 12:12:12', '%Y-%m-%d %H:%M:%S')print(day)# datetime转换为strnow = datetime.now()print(now.strftime('%a,%b %d %H:%M'))# datetime加减# 加减可以直接用+和-运算符，不过需要导入timedelta这个类from datetime import datetime, timedelta,timezonenow = datetime.now()print(now)# 增加时间add = now + timedelta(hours=10)print(add)# 减时间jian = now - timedelta(days=1)print(jian)add = now + timedelta(days=2, hours=12)print(add)#本地时间转换为UTC时间#一个datetime类型有一个时区属性tzinfo，# 但是默认为None，所以无法区分这个datetime到底是哪个时区，除非强行给datetime设置一个时区tz_zone = timezone(timedelta(hours=8))now = datetime.now()print(now)#强制设置时区dt = now.replace(tzinfo=tz_zone)print(dt)#时区转换#我们可以先通过utcnow()拿到当前的UTC时间，再转换为任意时区的时间#零时区#时区转换的关键在于，拿到一个datetime时，要获知其正确的时区，然后强制设置时区，作为基准时间。# 利用带时区的datetime，通过astimezone()方法，可以转换到任意时区。utc_dt = datetime.utcnow().replace(tzinfo=timezone.utc)print(utc_dt)# astimezone()将转换时区为北京时间:bj = utc_dt.astimezone(timezone(timedelta(hours=8)))print(bj)jp = utc_dt.astimezone(timezone(timedelta(hours=9)))print(jp) 小结 datetime表示的时间需要时区信息才能确定一个特定的时间，否则只能视为本地时间。 如果要存储datetime，最佳方法是将其转换为timestamp再存储，因为timestamp的值与时区完全无关。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[正则表达式]]></title>
      <url>%2F2016%2F12%2F16%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[在正则表达式中，如果直接给出字符，就是精确匹配。用\d可以匹配一个数字，\w可以匹配一个字母或数字，所以： ‘00\d’可以匹配’007’，但无法匹配’00A’； ‘\d\d\d’可以匹配’010’； ‘\w\w\d’可以匹配’py3’； .可以匹配任意字符，所以： ‘py.’可以匹配’pyc’、’pyo’、’py!’等等。要匹配变长的字符，在正则表达式中，用*表示任意个字符（包括0个），用+表示至少一个字符，用?表示0个或1个字符，用{n}表示n个字符，用{n,m}表示n-m个字符： 来看一个复杂的例子：\d{3}\s+\d{3,8}。 我们来从左到右解读一下： \d{3}表示匹配3个数字，例如’010’； \s可以匹配一个空格（也包括Tab等空白符），所以\s+表示至少有一个空格，例如匹配’ ‘，’ ‘等； \d{3,8}表示3-8个数字，例如’1234567’。 综合起来，上面的正则表达式可以匹配以任意个空格隔开的带区号的电话号码。 如果要匹配’010-12345’这样的号码呢？由于’-‘是特殊字符，在正则表达式中，要用’\’转义，所以，上面的正则是\d{3}-\d{3,8}。 但是，仍然无法匹配’010 - 12345’，因为带有空格。所以我们需要更复杂的匹配方式。 进阶 要做更精确地匹配，可以用[]表示范围，比如： [0-9a-zA-Z_]可以匹配一个数字、字母或者下划线； [0-9a-zA-Z_]+可以匹配至少由一个数字、字母或者下划线组成的字符串，比如’a100’，’0_Z’，’Py3000’等等； [a-zA-Z_][0-9a-zA-Z_]*可以匹配由字母或下划线开头，后接任意个由一个数字、字母或者下划线组成的字符串，也就是Python合法的变量； [a-zA-Z_][0-9a-zA-Z_]{0, 19}更精确地限制了变量的长度是1-20个字符（前面1个字符+后面最多19个字符）。 A|B可以匹配A或B，所以(P|p)ython可以匹配’Python’或者’python’。 ^表示行的开头，^\d表示必须以数字开头。 $表示行的结束，\d$表示必须以数字结束。 你可能注意到了，py也可以匹配’python’，但是加上^py$就变成了整行匹配，就只能匹配’py’了。 re模块 有了准备知识，我们就可以在Python中使用正则表达式了。Python提供re模块，包含所有正则表达式的功能。由于Python的字符串本身也用\转义，所以要特别注意： s = ‘ABC\-001’ # Python的字符串 对应的正则表达式字符串变成：‘ABC-001’因此我们强烈建议使用Python的r前缀，就不用考虑转义的问题了： s = r’ABC-001’ # Python的字符串 对应的正则表达式字符串不变：‘ABC-001’先看看如何判断正则表达式是否匹配： import rere.match(r’^\d{3}-\d{3,8}$’, ‘010-12345’) re.match(r’^\d{3}-\d{3,8}$’, ‘010 12345’) match()方法判断是否匹配，如果匹配成功，返回一个Match对象，否则返回None。常见的判断方法就是： test = ‘用户输入的字符串’if re.match(r’正则表达式’, test): print(‘ok’)else: print(‘failed’)切分字符串 用正则表达式切分字符串比用固定的字符更灵活，请看正常的切分代码： ‘a b c’.split(‘ ‘)[‘a’, ‘b’, ‘’, ‘’, ‘c’]嗯，无法识别连续的空格，用正则表达式试试： re.split(r’\s+’, ‘a b c’)[‘a’, ‘b’, ‘c’]无论多少个空格都可以正常分割。加入,试试： re.split(r’[\s\,]+’, ‘a,b, c d’)[‘a’, ‘b’, ‘c’, ‘d’]再加入;试试： re.split(r’[\s\,\;]+’, ‘a,b;; c d’)[‘a’, ‘b’, ‘c’, ‘d’]如果用户输入了一组标签，下次记得用正则表达式来把不规范的输入转化成正确的数组。 分组 除了简单地判断是否匹配之外，正则表达式还有提取子串的强大功能。用()表示的就是要提取的分组（Group）。比如： ^(\d{3})-(\d{3,8})$分别定义了两个组，可以直接从匹配的字符串中提取出区号和本地号码： m = re.match(r’^(\d{3})-(\d{3,8})$’, ‘010-12345’)m m.group(0)‘010-12345’m.group(1)‘010’m.group(2)‘12345’如果正则表达式中定义了组，就可以在Match对象上用group()方法提取出子串来。 注意到group(0)永远是原始字符串，group(1)、group(2)……表示第1、2、……个子串。 提取子串非常有用。来看一个更凶残的例子： t = ‘19:05:30’m = re.match(r’^(0[0-9]|1[0-9]|2[0-3]|[0-9])\:(0[0-9]|1[0-9]|2[0-9]|3[0-9]|4[0-9]|5[0-9]|[0-9])\:(0[0-9]|1[0-9]|2[0-9]|3[0-9]|4[0-9]|5[0-9]|[0-9])$’, t)m.groups()(‘19’, ‘05’, ‘30’)这个正则表达式可以直接识别合法的时间。但是有些时候，用正则表达式也无法做到完全验证，比如识别日期： ‘^(0[1-9]|1[0-2]|[0-9])-(0[1-9]|1[0-9]|2[0-9]|3[0-1]|[0-9])$’对于’2-30’，’4-31’这样的非法日期，用正则还是识别不了，或者说写出来非常困难，这时就需要程序配合识别了。 贪婪匹配 最后需要特别指出的是，正则匹配默认是贪婪匹配，也就是匹配尽可能多的字符。举例如下，匹配出数字后面的0： re.match(r’^(\d+)(0)$’, ‘102300’).groups()(‘102300’, ‘’)由于\d+采用贪婪匹配，直接把后面的0全部匹配了，结果0只能匹配空字符串了。 必须让\d+采用非贪婪匹配（也就是尽可能少匹配），才能把后面的0匹配出来，加个?就可以让\d+采用非贪婪匹配： re.match(r’^(\d+?)(0*)$’, ‘102300’).groups()(‘1023’, ‘00’)编译 当我们在Python中使用正则表达式时，re模块内部会干两件事情： 编译正则表达式，如果正则表达式的字符串本身不合法，会报错； 用编译后的正则表达式去匹配字符串。 如果一个正则表达式要重复使用几千次，出于效率的考虑，我们可以预编译该正则表达式，接下来重复使用时就不需要编译这个步骤了，直接匹配： import re 编译:re_telephone = re.compile(r’^(\d{3})-(\d{3,8})$’) 使用：re_telephone.match(‘010-12345’).groups()(‘010’, ‘12345’)re_telephone.match(‘010-8086’).groups()(‘010’, ‘8086’)编译后生成Regular Expression对象，由于该对象自己包含了正则表达式，所以调用对应的方法时不用给出正则字符串。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[分布式进程]]></title>
      <url>%2F2016%2F12%2F16%2F%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%9B%E7%A8%8B%2F</url>
      <content type="text"><![CDATA[在Thread和Process中，应当优选Process，因为Process更稳定，而且，Process可以分布到多台机器上，而Thread最多只能分布到同一台机器的多个CPU上。 Python的multiprocessing模块不但支持多进程，其中managers子模块还支持把多进程分布到多台机器上。一个服务进程可以作为调度者，将任务分布到其他多个进程中，依靠网络通信。 举个例子：如果我们已经有一个通过Queue通信的多进程程序在同一台机器上运行，现在，由于处理任务的进程任务繁重，希望把发送任务的进程和处理任务的进程分布到两台机器上。怎么用分布式进程实现？ 原有的Queue可以继续使用，但是，通过managers模块把Queue通过网络暴露出去，就可以让其他机器的进程访问Queue了。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import random, time, queuefrom multiprocessing import freeze_supportfrom multiprocessing.managers import BaseManager# 发送任务的队列:task_queue = queue.Queue()# 接收结果的队列:result_queue = queue.Queue()# 从BaseManager继承的QueueManager:class QueueManager(BaseManager): passdef return_task_queue(): global task_queue return task_queuedef return_result_queue(): global result_queue return result_queuedef test(): # 把两个Queue都注册到网络上, callable参数关联了Queue对象: QueueManager.register('get_task_queue', callable=return_task_queue) QueueManager.register('get_result_queue', callable=return_result_queue) # 绑定端口5000, 设置验证码'abc': manager = QueueManager(address=('127.0.0.1', 5000), authkey=b'abc') # 启动Queue: manager.start() # 获得通过网络访问的Queue对象: task = manager.get_task_queue() result = manager.get_result_queue() # 放几个任务进去: for i in range(10): n = random.randint(0, 10000) print('Put task %d...' % n) task.put(n) # 从result队列读取结果: print('Try get results...') for i in range(10): r = result.get(timeout=10) print('Result: %s' % r) # 关闭: manager.shutdown() print('master exit.')if __name__ == '__main__': freeze_support() test() 请注意，当我们在一台机器上写多进程程序时，创建的Queue可以直接拿来用，但是，在分布式多进程环境下，添加任务到Queue不可以直接对原始的task_queue进行操作，那样就绕过了QueueManager的封装，必须通过manager.get_task_queue()获得的Queue接口添加。 然后，在另一台机器上启动任务进程（本机上启动也可以）：1234567891011121314151617181920212223242526272829303132333435# task_worker.pyimport time, sys, queuefrom multiprocessing.managers import BaseManager# 创建类似的QueueManager:class QueueManager(BaseManager): pass# 由于这个QueueManager只从网络上获取Queue，所以注册时只提供名字:QueueManager.register('get_task_queue')QueueManager.register('get_result_queue')# 连接到服务器，也就是运行task_master.py的机器:server_addr = '127.0.0.1'print('Connect to server %s...' % server_addr)# 端口和验证码注意保持与task_master.py设置的完全一致:m = QueueManager(address=(server_addr, 5000), authkey=b'abc')# 从网络连接:m.connect()# 获取Queue的对象:task = m.get_task_queue()result = m.get_result_queue()# 从task队列取任务,并把结果写入result队列:for i in range(10): try: n = task.get(timeout=1) print('run task %d * %d...' % (n, n)) r = '%d * %d = %d' % (n, n, n*n) time.sleep(1) result.put(r) except Queue.Empty: print('task queue is empty.')# 处理结束:print('worker exit.') 任务进程要通过网络连接到服务进程，所以要指定服务进程的IP。 现在，可以试试分布式进程的工作效果了。先启动task_master.py服务进程：123456789101112131415161718192021222324252627282930313233343536373839$ python3 task_master.py Put task 3411...Put task 1605...Put task 1398...Put task 4729...Put task 5300...Put task 7471...Put task 68...Put task 4219...Put task 339...Put task 7866...Try get results...task_master.py进程发送完任务后，开始等待result队列的结果。现在启动task_worker.py进程：$ python3 task_worker.pyConnect to server 127.0.0.1...run task 3411 * 3411...run task 1605 * 1605...run task 1398 * 1398...run task 4729 * 4729...run task 5300 * 5300...run task 7471 * 7471...run task 68 * 68...run task 4219 * 4219...run task 339 * 339...run task 7866 * 7866...worker exit.task_worker.py进程结束，在task_master.py进程中会继续打印出结果：Result: 3411 * 3411 = 11634921Result: 1605 * 1605 = 2576025Result: 1398 * 1398 = 1954404Result: 4729 * 4729 = 22363441Result: 5300 * 5300 = 28090000Result: 7471 * 7471 = 55815841Result: 68 * 68 = 4624Result: 4219 * 4219 = 17799961Result: 339 * 339 = 114921Result: 7866 * 7866 = 61873956 这个简单的Master/Worker模型有什么用？其实这就是一个简单但真正的分布式计算，把代码稍加改造，启动多个worker，就可以把任务分布到几台甚至几十台机器上，比如把计算n*n的代码换成发送邮件，就实现了邮件队列的异步发送。 Queue对象存储在哪？注意到task_worker.py中根本没有创建Queue的代码，所以，Queue对象存储在task_master.py进程中： 而Queue之所以能通过网络访问，就是通过QueueManager实现的。由于QueueManager管理的不止一个Queue，所以，要给每个Queue的网络调用接口起个名字，比如get_task_queue。 authkey有什么用？这是为了保证两台机器正常通信，不被其他机器恶意干扰。如果task_worker.py的authkey和task_master.py的authkey不一致，肯定连接不上。 小结Python的分布式进程接口简单，封装良好，适合需要把繁重任务分布到多台机器的环境下。 注意Queue的作用是用来传递任务和接收结果，每个任务的描述数据量要尽量小。比如发送一个处理日志文件的任务，就不要发送几百兆的日志文件本身，而是发送日志文件存放的完整路径，由Worker进程再去共享的磁盘上读取文件。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ThreadLocal]]></title>
      <url>%2F2016%2F12%2F16%2FThreadLocal%2F</url>
      <content type="text"><![CDATA[ThreadLocal:解决函数中的传递问题123456789101112131415161718192021222324252627ThreadLocal帮你自动做这件事：import threading# 创建全局ThreadLocal对象:local_school = threading.local()def process_student(): # 获取当前线程关联的student: std = local_school.student print('Hello, %s (in %s)' % (std, threading.current_thread().name))def process_thread(name): # 绑定ThreadLocal的student: local_school.student = name process_student()t1 = threading.Thread(target= process_thread, args=('Alice',), name='Thread-A')t2 = threading.Thread(target= process_thread, args=('Bob',), name='Thread-B')t1.start()t2.start()t1.join()t2.join()执行结果：Hello, Alice (in Thread-A)Hello, Bob (in Thread-B) ThreadLocal最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等，这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源。 小结一个ThreadLocal变量虽然是全局变量，但每个线程都只能读写自己线程的独立副本，互不干扰。ThreadLocal解决了参数在一个线程中各个函数之间互相传递的问题。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[多线程]]></title>
      <url>%2F2016%2F12%2F15%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%2F</url>
      <content type="text"><![CDATA[多任务可以由多进程完成，也可以由一个进程内的多线程完成。Python的标准库提供了两个模块：_thread和threading，_thread是低级模块，threading是高级模块，对_thread进行了封装。绝大多数情况下使用threading这个高级模块。 1234567891011121314151617181920212223242526# -*- coding=utf-8 -*-'多线程'# threading的使用import time, threadingdef loop(): print('thrad %s running' % threading.current_thread().name) n = 0 while n &lt; 5: n += 1 print('thread %s &gt;&gt;&gt; %s' % (threading.current_thread().name, n)) time.sleep(1) print('thread %s ended' % threading.current_thread().name)print('current thread %s' % threading.current_thread().name)# 子线程实例化# 传入线程loop，传入线程名称（不传入也可以）t = threading.Thread(target=loop, name='MyThread')t.start()# 线程同步t.join()print('thread %s ended' % threading.current_thread().name) Lock线程锁不加线程锁的问题：线程执行多条语句时，可能导致线程中断，从而导致多个线程把同一个对象的内容改乱了（导致内容不一致）threading.Lock()的好处？线程锁只有一个，无论多少线程，同一时刻最多只有一个线程持有该锁，所以，不会造成修改的冲突1234567891011121314151617181920212223242526272829# 假定这是你的银行存款:balance = 0# 线程锁lock = threading.Lock()def change_it(n): # 先存后取，结果应该为0: global balance balance = balance + n balance = balance - ndef run_thread(n): for i in range(100000): # 先获取锁 lock.acquire() try: change_it(n) finally: #释放线程锁 lock.release()t1 = threading.Thread(target=run_thread, args=(5,))t2 = threading.Thread(target=run_thread, args=(8,))t1.start()t2.start()t1.join()t2.join()print(balance) 锁的好处就是确保了某段关键代码只能由一个线程从头到尾完整地执行，坏处当然也很多，首先是阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了。其次，由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁，导致多个线程全部挂起，既不能执行，也无法结束，只能靠操作系统强制终止。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[多进程]]></title>
      <url>%2F2016%2F12%2F15%2F%E5%A4%9A%E8%BF%9B%E7%A8%8B%2F</url>
      <content type="text"><![CDATA[————-方式一 —————-fork():普通的函数调用，调用一次，返回一次，但是fork()调用一次，返回两次，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），然后，分别在父进程和子进程内返回。 子进程永远返回0，而父进程返回子进程的ID。这样做的理由是，一个父进程可以fork出很多子进程，所以，父进程要记下每个子进程的ID，而子进程只需要调用getppid()就可以拿到父进程的ID。123456789101112print('Process (%s) start...' % os.getpid())#fork()调用一次，返回两次，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程）# ，然后，分别在父进程和子进程内返回。pid = os.fork()print(pid)if pid == 0: #pid代表子线程，ppid代表父线程 print('I am child process (%s) and my parent is %s.' % (os.getpid(), os.getppid()))else: print('I (%s) just created a child process (%s).' % (os.getpid(), pid)) multiprocessing模块提供了一个Process类来代表一个进程对象 ————-方式二—————-1234567891011121314151617#multiprocessing模块提供了一个Process类来代表一个进程对象#子线程执行代码def run_process(name): print('chile process ...',name,os.getpid())if __name__=='__main__': print('parent ...',os.getpid())#创建子进程时，只需要传入一个执行函数和函数的参数，创建一个Process实例，# 用start()方法启动，这样创建进程比fork()还要简单。# join()方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步。 p = Process(target=run_process,args=('test',)) print('chile process start') p.start() p.join() print('chile process end') ————-方式三—————-12345678910111213141516171819202122#线程池#pool如果要启动大量的子进程，可以用进程池的方式批量创建子进程：from multiprocessing import Poolimport os, time, randomdef long_time_task(name): print('Run task %s (%s)...' % (name, os.getpid())) start = time.time() time.sleep(random.random() * 3) end = time.time() print('Task %s runs %0.2f seconds.' % (name, (end - start)))if __name__=='__main__': print('Parent process %s.' % os.getpid()) p = Pool(8) for i in range(9): p.apply_async(long_time_task, args=(i,)) print('Waiting for all subprocesses done...') p.close() p.join() print('All subprocesses done.') ————-子进程—————-很多时候，子进程并不是自身，而是一个外部进程。我们创建了子进程后，还需要控制子进程的输入和输出。 subprocess模块可以让我们非常方便地启动一个子进程，然后控制其输入和输出。12345678910111213141516171819import subprocessprint('$ nslookup www.python.org')r = subprocess.call(['nslookup', 'www.python.org'])print('Exit code:', r)print('$ nslookup')p = subprocess.Popen(['nslookup'], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)output, err = p.communicate(b'set q=mx\npython.org\nexit\n')print(output.decode('utf-8'))print('Exit code:', p.returncode)#上面的代码相当于在命令行执行命令nslookup，然后手动输入：# set q=mx# python.org# exit 进程间通信Process之间肯定是需要通信的，操作系统提供了很多机制来实现进程间的通信。Python的multiprocessing模块包装了底层的机制，提供了Queue、Pipes等多种方式来交换数据。进程间通信 Process之间肯定是需要通信的，操作系统提供了很多机制来实现进程间的通信。Python的multiprocessing模块包装了底层的机制，提供了Queue、Pipes等多种方式来交换数据。 我们以Queue为例，在父进程中创建两个子进程，一个往Queue里写数据，一个从Queue里读数据：123456789101112131415161718192021222324252627282930313233343536373839404142from multiprocessing import Process, Queueimport os, time, random# 写数据进程执行的代码:def write(q): print('Process to write: %s' % os.getpid()) for value in ['A', 'B', 'C']: print('Put %s to queue...' % value) q.put(value) time.sleep(random.random())# 读数据进程执行的代码:def read(q): print('Process to read: %s' % os.getpid()) while True: value = q.get(True) print('Get %s from queue.' % value)if __name__=='__main__': # 父进程创建Queue，并传给各个子进程： q = Queue() pw = Process(target=write, args=(q,)) pr = Process(target=read, args=(q,)) # 启动子进程pw，写入: pw.start() # 启动子进程pr，读取: pr.start() # 等待pw结束: pw.join() # pr进程里是死循环，无法等待其结束，只能强行终止: pr.terminate()运行结果如下：Process to write: 50563Put A to queue...Process to read: 50564Get A from queue.Put B to queue...Get B from queue.Put C to queue...Get C from queue. 在Unix/Linux下，multiprocessing模块封装了fork()调用，使我们不需要关注fork()的细节。由于Windows没有fork调用，因此，multiprocessing需要“模拟”出fork的效果，父进程所有Python对象都必须通过pickle序列化再传到子进程去，所有，如果multiprocessing在Windows下调用失败了，要先考虑是不是pickle失败了。 小结在Unix/Linux下，可以使用fork()调用实现多进程。 要实现跨平台的多进程，可以使用multiprocessing模块。 进程间通信是通过Queue、Pipes等实现的。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[序列化]]></title>
      <url>%2F2016%2F12%2F15%2F%E5%BA%8F%E5%88%97%E5%8C%96%2F</url>
      <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243# -*- coding=utf-8 -*-'序列化packling,反序列化unpackling''使用pickle模块实现'import pickleimport jsond = dict(name='name')#序列化到文件with open('pickle.txt','wb') as f : pickle.dump(d,f)#反序列化with open('pickle.txt','rb') as f: print(pickle.load(f))#序列化对象p = pickle.dumps(d)print(p)#反序列化p2 = pickle.loads(p)print(p2)#python转换为jsonD = dict(name='name',age='19',score = '100')#转换为jsonj = json.dumps(D)print(j)#转换为python对象j2 = json.loads(j)print(j2)#将json写入到文件with open('json.txt','w') as f: json.dump(D,f)#从文件中读取回python对象with open('json.txt','r') as f: print(json.load(f)) JSON进阶1234567891011121314151617181920212223242526272829303132class Student(object): def __init__(self,name,age,score): self.name = name self.age = age self.score = scores = Student('name',1,100)#json无法直接序列化class，报错# print(json.dumps(s))#简便方法：把任意class的实例变为dictprint(json.dumps(s,default=lambda obj:obj.__dict__))#可选参数default就是把任意一个对象变成一个可序列为JSON的对象def student2dict(stu): return &#123; 'name':stu.name ,'age':stu.age ,'score':stu.score &#125;s = json.dumps(s,default=student2dict)print(s)print('json',json.loads(s))#传入的object_hook函数负责把dict转换为Student实例：def dict2student(d): return Student(d['name'], d['age'], d['score'])json_str = '&#123;"age": 20, "score": 88, "name": "Bob"&#125;'print(json.loads(json_str, object_hook=dict2student)) 小结Python语言特定的序列化模块是pickle，但如果要把序列化搞得更通用、更符合Web标准，就可以使用json模块。 json模块的dumps()和loads()函数是定义得非常好的接口的典范。当我们使用时，只需要传入一个必须的参数。但是，当默认的序列化或反序列机制不满足我们的要求时，我们又可以传入更多的参数来定制序列化或反序列化的规则，既做到了接口简单易用，又做到了充分的扩展性和灵活性。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[操作文件和目录]]></title>
      <url>%2F2016%2F12%2F15%2F%E6%93%8D%E4%BD%9C%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95%2F</url>
      <content type="text"><![CDATA[‘操作文件和目录’12345678910111213141516171819202122import os#操作系统类型print(os.name)#详细的系统信息print(os.uname())#获取环境变量print(os.environ)#获取指定的环境变量print(os.environ.get('PATH'))print(os.environ.get('x','default'))#操作文件和目录#绝对路径print(os.path.abspath('.'))#在某个目录下创建一个新目录,把完整路径表示出来print(os.path.join('/Users/black/PythonProjects/Hello2','osCreate'))#创建# os.mkdir('/Users/black/PythonProjects/Hello2/osCreate')#删除os.rmdir('/Users/black/PythonProjects/Hello2/osCreate') 把两个路径合成一个时，不要直接拼字符串，而要通过os.path.join()函数，这样可以正确处理不同操作系统的路径分隔符。同样的道理，要拆分路径时，也不要直接去拆字符串，而要通过os.path.split()函数，这样可以把一个路径拆分为两部分，后一部分总是最后级别的目录或文件名：12345&gt;&gt;&gt; os.path.split('/Users/michael/testdir/file.txt')('/Users/michael/testdir', 'file.txt')#列出当前目录的所有文件l = [x for x in os.listdir('.') if os.path.isdir(x)]print(l) 列出所有py文件12l2 = [x for x in os.listdir(&apos;.&apos;) if os.path.isfile(x) and os.path.splitext(x)[1]==&apos;.py&apos;]print(l2) 在目录下查找指定字符串123456789def enterdir(path,word): for x in os.listdir(path): subpath=os.path.join(os.path.abspath(path),x) if os.path.isdir(subpath): enterdir(subpath,word) else: if word in x: print(subpath)enterdir('/Users/black/PythonProjects/Hello2','debugging')]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[StringIO和BytesIO]]></title>
      <url>%2F2016%2F12%2F15%2FStringIO%E5%92%8CBytesIO%2F</url>
      <content type="text"><![CDATA[StringIO很多时候，数据读写不一定是文件，也可以在内存中读写。 StringIO顾名思义就是在内存中读写str。 要把str写入StringIO，我们需要先创建一个StringIO，然后，像文件一样写入即可：12345678910&gt;&gt;&gt; from io import StringIO&gt;&gt;&gt; f = StringIO()&gt;&gt;&gt; f.write('hello')5&gt;&gt;&gt; f.write(' ')1&gt;&gt;&gt; f.write('world!')6&gt;&gt;&gt; print(f.getvalue())hello world! getvalue()方法用于获得写入后的str。 BytesIOStringIO操作的只能是str，如果要操作二进制数据，就需要使用BytesIO。 BytesIO实现了在内存中读写bytes，我们创建一个BytesIO，然后写入一些bytes：123456&gt;&gt;&gt; from io import BytesIO&gt;&gt;&gt; f = BytesIO()&gt;&gt;&gt; f.write('中文'.encode('utf-8'))6&gt;&gt;&gt; print(f.getvalue())b'\xe4\xb8\xad\xe6\x96\x87' 请注意，写入的不是str，而是经过UTF-8编码的bytes。 和StringIO类似，可以用一个bytes初始化BytesIO，然后，像读文件一样读取：1234&gt;&gt;&gt; from io import BytesIO&gt;&gt;&gt; f = BytesIO(b'\xe4\xb8\xad\xe6\x96\x87')&gt;&gt;&gt; f.read()b'\xe4\xb8\xad\xe6\x96\x87' 小结StringIO和BytesIO是在内存中操作str和bytes的方法，使得和读写文件具有一致的接口。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[IO操作]]></title>
      <url>%2F2016%2F12%2F15%2FIO%E6%93%8D%E4%BD%9C%2F</url>
      <content type="text"><![CDATA[由于文件读写时都有可能产生IOError，一旦出错，后面的f.close()就不会调用。所以，为了保证无论是否出错都能正确地关闭文件，我们可以使用try … finally来实现：123456try: f = open('/path/to/file', 'r') print(f.read())finally: if f: f.close() 但是每次都这么写实在太繁琐，所以，Python引入了with语句来自动帮我们调用close()方法：12with open('/path/to/file', 'r') as f: print(f.read()) 这和前面的try … finally是一样的，但是代码更佳简洁，并且不必调用f.close()方法。 调用read()会一次性读取文件的全部内容，如果文件有10G，内存就爆了，所以，要保险起见，可以反复调用read(size)方法，每次最多读取size个字节的内容。另外，调用readline()可以每次读取一行内容，调用readlines()一次读取所有内容并按行返回list。因此，要根据需要决定怎么调用。 如果文件很小，read()一次性读取最方便；如果不能确定文件大小，反复调用read(size)比较保险；如果是配置文件，调用readlines()最方便：12for line in f.readlines(): print(line.strip()) # 把末尾的'\n'删掉 二进制文件前面讲的默认都是读取文本文件，并且是UTF-8编码的文本文件。要读取二进制文件，比如图片、视频等等，用’rb’模式打开文件即可：123&gt;&gt;&gt; f = open('/Users/michael/test.jpg', 'rb')&gt;&gt;&gt; f.read()b'\xff\xd8\xff\xe1\x00\x18Exif\x00\x00...' # 十六进制表示的字节 字符编码要读取非UTF-8编码的文本文件，需要给open()函数传入encoding参数，例如，读取GBK编码的文件：12&gt;&gt;&gt; f = open('/Users/michael/gbk.txt', 'r', encoding='gbk')&gt;&gt;&gt; f.read() ‘测试’遇到有些编码不规范的文件，你可能会遇到UnicodeDecodeError，因为在文本文件中可能夹杂了一些非法编码的字符。遇到这种情况，open()函数还接收一个errors参数，表示如果遇到编码错误后如何处理。最简单的方式是直接忽略：1&gt;&gt;&gt; f = open('/Users/michael/gbk.txt', 'r', encoding='gbk', errors='ignore') 写文件写文件和读文件是一样的，唯一区别是调用open()函数时，传入标识符’w’或者’wb’表示写文本文件或写二进制文件：123&gt;&gt;&gt; f = open('/Users/michael/test.txt', 'w')&gt;&gt;&gt; f.write('Hello, world!')&gt;&gt;&gt; f.close() 你可以反复调用write()来写入文件，但是务必要调用f.close()来关闭文件。当我们写文件时，操作系统往往不会立刻把数据写入磁盘，而是放到内存缓存起来，空闲的时候再慢慢写入。只有调用close()方法时，操作系统才保证把没有写入的数据全部写入磁盘。忘记调用close()的后果是数据可能只写了一部分到磁盘，剩下的丢失了。所以，还是用with语句来得保险：12with open('/Users/michael/test.txt', 'w') as f: f.write('Hello, world!') 要写入特定编码的文本文件，请给open()函数传入encoding参数，将字符串自动转换成指定编码。 小结在Python中，文件读写是通过open()函数打开的文件对象完成的。使用with语句操作文件IO是个好习惯。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[调试]]></title>
      <url>%2F2016%2F12%2F15%2F%E8%B0%83%E8%AF%95%2F</url>
      <content type="text"><![CDATA[1.断言（assert）：1234567def foo(s): n = int(s) assert n != 0, 'n is zero!' return 10 / ndef main(): foo('0') assert的意思是，表达式n != 0应该是True，否则，根据程序运行的逻辑，后面的代码肯定会出错。 如果断言失败，assert语句本身就会抛出AssertionError 2.日志: logging和assert比，logging不会抛出错误，而且可以输出到文件123456789101112131415import logging#添加处理等级logging.basicConfig(level=logging.INFO)s = '0'n = int(s)logging.info('n = %d'% n)print(10/n)处理结果：$ python3 err.pyINFO:root:n = 0Traceback (most recent call last): File "err.py", line 8, in &lt;module&gt; print(10 / n)ZeroDivisionError: division by zero 这就是logging的好处，它允许你指定记录信息的级别，有debug，info，warning，error等几个级别，当我们指定level=INFO时，logging.debug就不起作用了。同理，指定level=WARNING后，debug和info就不起作用了。这样一来，你可以放心地输出不同级别的信息，也不用删除，最后统一控制输出哪个级别的信息。 logging的另一个好处是通过简单的配置，一条语句可以同时输出到不同的地方，比如console和文件。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[错误处理]]></title>
      <url>%2F2016%2F12%2F15%2F%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86%2F</url>
      <content type="text"><![CDATA[1234567891011121314try...except...finally...的错误处理机制，Python也不例外。抛出错误 raise# err_raise.pyclass FooError(ValueError): passdef foo(s): n = int(s) if n==0: raise FooError('invalid value: %s' % s) return 10 / nfoo('0') 小结 Python内置的try…except…finally用来处理错误十分方便。出错时，会分析错误信息并定位错误发生的代码位置才是最关键的。 程序也可以主动抛出错误，让调用者来处理相应的错误。但是，应该在文档中写清楚可能会抛出哪些错误，以及错误产生的原因。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[面向对象高级编程之使用元类]]></title>
      <url>%2F2016%2F12%2F13%2F%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E4%B9%8B%E4%BD%BF%E7%94%A8%E5%85%83%E7%B1%BB%2F</url>
      <content type="text"><![CDATA[type()动态语言和静态语言最大的不同，就是函数和类的定义，不是编译时定义的，而是运行时动态创建的。 比方说我们要定义一个Hello的class，就写一个hello.py模块：123class Hello(object): def hello(self, name='world'): print('Hello, %s.' % name) 当Python解释器载入hello模块时，就会依次执行该模块的所有语句，执行结果就是动态创建出一个Hello的class对象，测试如下： 12345678&gt;&gt;&gt; from hello import Hello&gt;&gt;&gt; h = Hello()&gt;&gt;&gt; h.hello()Hello, world.&gt;&gt;&gt; print(type(Hello))&lt;class 'type'&gt;&gt;&gt;&gt; print(type(h))&lt;class 'hello.Hello'&gt; type()函数可以查看一个类型或变量的类型，Hello是一个class，它的类型就是type，而h是一个实例，它的类型就是class Hello。 我们说class的定义是运行时动态创建的，而创建class的方法就是使用type()函数。 type()函数既可以返回一个对象的类型，又可以创建出新的类型，比如，我们可以通过type()函数创建出Hello类，而无需通过class Hello(object)…的定义：1234567891011&gt;&gt;&gt; def fn(self, name='world'): # 先定义函数... print('Hello, %s.' % name)...&gt;&gt;&gt; Hello = type('Hello', (object,), dict(hello=fn)) # 创建Hello class&gt;&gt;&gt; h = Hello()&gt;&gt;&gt; h.hello()Hello, world.&gt;&gt;&gt; print(type(Hello))&lt;class 'type'&gt;&gt;&gt;&gt; print(type(h))&lt;class '__main__.Hello'&gt; 要创建一个class对象，type()函数依次传入3个参数： class的名称；继承的父类集合，注意Python支持多重继承，如果只有一个父类，别忘了tuple的单元素写法；class的方法名称与函数绑定，这里我们把函数fn绑定到方法名hello上。通过type()函数创建的类和直接写class是完全一样的，因为Python解释器遇到class定义时，仅仅是扫描一下class定义的语法，然后调用type()函数创建出class。 正常情况下，我们都用class Xxx…来定义类，但是，type()函数也允许我们动态创建出类来，也就是说，动态语言本身支持运行期动态创建类，这和静态语言有非常大的不同，要在静态语言运行期创建类，必须构造源代码字符串再调用编译器，或者借助一些工具生成字节码实现，本质上都是动态编译，会非常复杂。 metaclass除了使用type()动态创建类以外，要控制类的创建行为，还可以使用metaclass。 metaclass，直译为元类，简单的解释就是： 当我们定义了类以后，就可以根据这个类创建出实例，所以：先定义类，然后创建实例。 但是如果我们想创建出类呢？那就必须根据metaclass创建出类，所以：先定义metaclass，然后创建类。 连接起来就是：先定义metaclass，就可以创建类，最后创建实例。 所以，metaclass允许你创建类或者修改类。换句话说，你可以把类看成是metaclass创建出来的“实例”。 metaclass是Python面向对象里最难理解，也是最难使用的魔术代码。正常情况下，你不会碰到需要使用metaclass的情况，所以，以下内容看不懂也没关系，因为基本上你不会用到。 我们先看一个简单的例子，这个metaclass可以给我们自定义的MyList增加一个add方法： 定义ListMetaclass，按照默认习惯，metaclass的类名总是以Metaclass结尾，以便清楚地表示这是一个metaclass：12345# metaclass是类的模板，所以必须从`type`类型派生：class ListMetaclass(type): def __new__(cls, name, bases, attrs): attrs['add'] = lambda self, value: self.append(value) return type.__new__(cls, name, bases, attrs) 有了ListMetaclass，我们在定义类的时候还要指示使用ListMetaclass来定制类，传入关键字参数metaclass：12class MyList(list, metaclass=ListMetaclass): pass 当我们传入关键字参数metaclass时，魔术就生效了，它指示Python解释器在创建MyList时，要通过ListMetaclass.new()来创建，在此，我们可以修改类的定义，比如，加上新的方法，然后，返回修改后的定义。 new()方法接收到的参数依次是： 当前准备创建的类的对象； 类的名字； 类继承的父类集合； 类的方法集合。 测试一下MyList是否可以调用add()方法： 1234&gt;&gt;&gt; L = MyList()&gt;&gt;&gt; L.add(1)&gt;&gt; L[1]]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[面型对象高级编程之使用__slots__]]></title>
      <url>%2F2016%2F12%2F12%2F%E9%9D%A2%E5%9E%8B%E5%AF%B9%E8%B1%A1%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E4%B9%8B%E4%BD%BF%E7%94%A8__slots__%2F</url>
      <content type="text"><![CDATA[面型对象高级编程之使用 __slots____slots__1.为了给该实例绑定任何属性和方法 2.可以限制__slots__用于限制该类实例的属性与方法，不能限制类本身和继承类实例的属性与方法12345678910111213141516171819202122class Student(): # 用tuple定义允许绑定的属性名称 __slots__ = ('name','age') s = Student()#创建新实例 s.name = 'Name'#绑定属性 s.age = 'Age' #由于s没用方法到参数中，所以报错 #s.s = 's' #使用__slots__要注意，__slots__定义的属性仅对当前类实例起作用 # ，对继承的子类是不起作用的： class Man(Student): pass m = Man() #m新创建的属性 m.s = 'a' #子类调用并不起作用，报错 print(m.s,m.name) 除非在子类中也定义slots，这样，子类实例允许定义的属性就是自身的slots加上父类的slots。]]></content>
    </entry>

    
  
  
</search>
